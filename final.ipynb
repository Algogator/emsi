{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, lit\n",
    "import lxml\n",
    "import lxml.etree\n",
    "import lxml.html\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "import pandas\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"sample\")\n",
    "map_onet = spark.read.csv(\"map_onet_soc.csv\", header = \"true\")\n",
    "soc_heir = spark.read.csv(\"soc_hierarchy.csv\", header = \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|      onet|   soc5|\n",
      "+----------+-------+\n",
      "|11-1011.00|11-1011|\n",
      "|11-1011.03|11-1011|\n",
      "|11-1021.00|11-1021|\n",
      "|11-1031.00|11-1031|\n",
      "|11-2011.00|11-2011|\n",
      "|11-2011.01|11-2011|\n",
      "|11-2021.00|11-2021|\n",
      "|11-2022.00|11-2022|\n",
      "|11-2031.00|11-2031|\n",
      "|11-3011.00|11-3011|\n",
      "|11-3021.00|11-3021|\n",
      "|11-3031.00|11-3031|\n",
      "|11-3031.01|11-3031|\n",
      "|11-3031.02|11-3031|\n",
      "|11-3051.00|11-3051|\n",
      "|11-3051.01|11-3051|\n",
      "|11-3051.02|11-3051|\n",
      "|11-3051.03|11-3051|\n",
      "|11-3051.04|11-3051|\n",
      "|11-3051.05|11-3051|\n",
      "+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "map_onet.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wasn't sure if pre-processing the mappings is allowed but converting the soc_hierarchy.csv to a dictionary will ensure contant lookup time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=BooleanType())\n",
    "def detect_html(s):\n",
    "    try:\n",
    "        return lxml.html.fromstring(s).find('.//*') is not None\n",
    "            \n",
    "    except lxml.etree.ParserError as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of documents from which you successfully removed HTML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4010"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(detect_html('body')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=StringType())\n",
    "def detect_html(s):\n",
    "    try:\n",
    "        if lxml.html.fromstring(s).find('.//*') is not None:\n",
    "            return str(lxml.html.document_fromstring(s).text_content())\n",
    "        else:\n",
    "            return s\n",
    "            \n",
    "    except lxml.etree.ParserError as e:\n",
    "        return s\n",
    "\n",
    "df = df.withColumn('body',detect_html(col('body')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing an inner join may not be very scalable, I assumed the mapping would be constant and fixed. I would have liked to have the mapping in a dictionary which would allow constant lookup time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soc5  = df.join(map_onet, on='onet', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------------+----------+----------+-----+--------------------+-------+\n",
      "|      onet|                body|               city|   expired|    posted|state|               title|   soc5|\n",
      "+----------+--------------------+-------------------+----------+----------+-----+--------------------+-------+\n",
      "|11-9199.00|Project Manager -...|             Laurel|2017-01-06|2016-12-07|   MD|Project Manager -...|11-9199|\n",
      "|13-1023.00|You can become an...|            Fairfax|2015-12-30|2015-11-30|   VA|Lease Purchase Dr...|13-1023|\n",
      "|19-3051.00|POSITION SUMMARY/...|      Ellicott City|2017-01-02|2016-12-03|   MD|Planning Supervis...|19-3051|\n",
      "|53-3032.00|Speak with a Recr...|            Jarales|2017-01-18|2016-12-19|   NM|Experienced Class...|53-3032|\n",
      "|11-3061.00|JOB SUMMARYThe Bu...|             Laredo|2017-01-02|2016-12-03|   TX|Buying Manager - ...|11-3061|\n",
      "|43-3021.02|Position Descript...|         Norristown|2017-03-23|2016-12-23|   PA|Senior Billing Re...|43-3021|\n",
      "|41-3031.02|Relationship bank...|          Los Altos|2016-12-16|2016-11-16|   CA|Greater South Bay...|41-3031|\n",
      "|35-3021.00|The Team Member i...|          Texarkana|2016-02-22|2016-01-23|   TX|Restaurant Team M...|35-3021|\n",
      "|41-2031.00|Position: Product...|           Appleton|2016-03-02|2016-02-01|   WI|Production Associate|41-2031|\n",
      "|13-1161.00|Requirements Pref...|        San Antonio|2016-12-28|2016-11-28|   TX|Program Marketing...|13-1161|\n",
      "|29-1141.00|Seeking Registere...|     Pleasant Ridge|2016-12-27|2016-11-27|   MI|     RN Travel Nurse|29-1141|\n",
      "|29-2091.00|Vacancy Identific...|        Martinsburg|2016-12-17|2016-11-17|   WV|Orthotist/Prosthe...|29-2091|\n",
      "|19-4099.01|Quality Assurance...|     Salt Lake City|2017-01-20|2016-12-21|   UT|Quality Assurance...|19-4099|\n",
      "|29-1141.00|Seeking Registere...|        East Quogue|2016-12-27|2016-11-27|   NY|     RN Travel Nurse|29-1141|\n",
      "|29-1141.00|Seeking Registere...|       San Elizario|2016-12-27|2016-11-27|   TX|     RN Travel Nurse|29-1141|\n",
      "|39-9031.00|Job Description:S...|          Ingleside|2016-12-17|2016-11-17|   TX|Personal Trainer ...|39-9031|\n",
      "|29-1141.00|Seeking Registere...|            Marquez|2016-12-27|2016-11-27|   TX|     RN Travel Nurse|29-1141|\n",
      "|43-4051.00|Position Informat...|      San Francisco|2017-01-22|2016-12-23|   CA|Customer Service ...|43-4051|\n",
      "|29-1141.00|Seeking Registere...|Grosse Ile Township|2016-12-27|2016-11-27|   MI|     RN Travel Nurse|29-1141|\n",
      "|41-1011.00|Generate Sales* P...|      Madeira Beach|2016-03-02|2016-02-01|   FL|  Lids Store Manager|41-1011|\n",
      "+----------+--------------------+-------------------+----------+----------+-----+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_soc5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed the soc2 code could be derived from the first two numbers in the soc5. I am assuming the there's a limit of 99-xxxx since this would break if it goes beyond 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_soc(c):\n",
    "  return c[:2] + '-0000'\n",
    "\n",
    "soc2 = udf(lambda x: find_soc(x), StringType())\n",
    "fin = df_soc5.withColumn('soc2', soc2(df_soc5.soc5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+--------------------+\n",
      "|  child| parent|level|                name|\n",
      "+-------+-------+-----+--------------------+\n",
      "|00-0000|00-0000|    1|Total, All Occupa...|\n",
      "|11-0000|00-0000|    2|Management Occupa...|\n",
      "|11-1000|11-0000|    3|      Top Executives|\n",
      "|11-1010|11-1000|    4|    Chief Executives|\n",
      "|11-1011|11-1010|    5|    Chief Executives|\n",
      "|11-1020|11-1000|    4|General and Opera...|\n",
      "|11-1021|11-1020|    5|General and Opera...|\n",
      "|11-1030|11-1000|    4|         Legislators|\n",
      "|11-1031|11-1030|    5|         Legislators|\n",
      "|11-2000|11-0000|    3|Advertising, Mark...|\n",
      "|11-2010|11-2000|    4|Advertising and P...|\n",
      "|11-2011|11-2010|    5|Advertising and P...|\n",
      "|11-2020|11-2000|    4|Marketing and Sal...|\n",
      "|11-2021|11-2020|    5|  Marketing Managers|\n",
      "|11-2022|11-2020|    5|      Sales Managers|\n",
      "|11-2030|11-2000|    4|Public Relations ...|\n",
      "|11-2031|11-2030|    5|Public Relations ...|\n",
      "|11-3000|11-0000|    3|Operations Specia...|\n",
      "|11-3010|11-3000|    4|Administrative Se...|\n",
      "|11-3011|11-3010|    5|Administrative Se...|\n",
      "+-------+-------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soc_heir.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|  child| parent|\n",
      "+-------+-------+\n",
      "|11-1011|11-1010|\n",
      "|11-1021|11-1020|\n",
      "|11-1031|11-1030|\n",
      "|11-2011|11-2010|\n",
      "|11-2021|11-2020|\n",
      "|11-2022|11-2020|\n",
      "|11-2031|11-2030|\n",
      "|11-3011|11-3010|\n",
      "|11-3021|11-3020|\n",
      "|11-3031|11-3030|\n",
      "|11-3051|11-3050|\n",
      "|11-3061|11-3060|\n",
      "|11-3071|11-3070|\n",
      "|11-3111|11-3110|\n",
      "|11-3121|11-3120|\n",
      "|11-3131|11-3130|\n",
      "|11-9013|11-9010|\n",
      "|11-9021|11-9020|\n",
      "|11-9031|11-9030|\n",
      "|11-9032|11-9030|\n",
      "+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s5 = soc_heir.filter(col(\"level\") == 5).select(\"child\", \"parent\").alias('5')\n",
    "s5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|  child| parent|\n",
      "+-------+-------+\n",
      "|11-1010|11-1000|\n",
      "|11-1020|11-1000|\n",
      "|11-1030|11-1000|\n",
      "|11-2010|11-2000|\n",
      "|11-2020|11-2000|\n",
      "|11-2030|11-2000|\n",
      "|11-3010|11-3000|\n",
      "|11-3020|11-3000|\n",
      "|11-3030|11-3000|\n",
      "|11-3050|11-3000|\n",
      "|11-3060|11-3000|\n",
      "|11-3070|11-3000|\n",
      "|11-3110|11-3000|\n",
      "|11-3120|11-3000|\n",
      "|11-3130|11-3000|\n",
      "|11-9010|11-9000|\n",
      "|11-9020|11-9000|\n",
      "|11-9030|11-9000|\n",
      "|11-9040|11-9000|\n",
      "|11-9050|11-9000|\n",
      "+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s4 = soc_heir.filter(col(\"level\") == 4).select(\"child\", \"parent\").alias('4')\n",
    "s4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|  child| parent|\n",
      "+-------+-------+\n",
      "|11-1000|11-0000|\n",
      "|11-2000|11-0000|\n",
      "|11-3000|11-0000|\n",
      "|11-9000|11-0000|\n",
      "|13-1000|13-0000|\n",
      "|13-2000|13-0000|\n",
      "|15-1100|15-0000|\n",
      "|15-2000|15-0000|\n",
      "|17-1000|17-0000|\n",
      "|17-2000|17-0000|\n",
      "|17-3000|17-0000|\n",
      "|19-1000|19-0000|\n",
      "|19-2000|19-0000|\n",
      "|19-3000|19-0000|\n",
      "|19-4000|19-0000|\n",
      "|21-1000|21-0000|\n",
      "|21-2000|21-0000|\n",
      "|23-1000|23-0000|\n",
      "|23-2000|23-0000|\n",
      "|25-1000|25-0000|\n",
      "+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s3 = soc_heir.filter(col(\"level\") == 3).select(\"child\", \"parent\").alias('3')\n",
    "s3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "s5.registerTempTable(\"s5\")\n",
    "s4.registerTempTable(\"s4\")\n",
    "\n",
    "tmp = spark.sql(\"select s5.child, s4.parent from s5  LEFT JOIN s4 ON s5.parent = s4.child\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.registerTempTable(\"s3\")\n",
    "tmp.registerTempTable(\"tmp\")\n",
    "\n",
    "soc2_map = spark.sql(\"select tmp.child, s3.parent from tmp  LEFT JOIN s3 ON tmp.parent = s3.child\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|parent |count|\n",
      "+-------+-----+\n",
      "|47-0000|326  |\n",
      "|11-0000|3940 |\n",
      "|21-0000|542  |\n",
      "|45-0000|13   |\n",
      "|15-0000|3603 |\n",
      "|25-0000|609  |\n",
      "|17-0000|981  |\n",
      "|51-0000|700  |\n",
      "|53-0000|9529 |\n",
      "|49-0000|1246 |\n",
      "|43-0000|4379 |\n",
      "|27-0000|717  |\n",
      "|29-0000|6960 |\n",
      "|13-0000|2233 |\n",
      "|37-0000|459  |\n",
      "|55-0000|22   |\n",
      "|23-0000|145  |\n",
      "|31-0000|940  |\n",
      "|39-0000|532  |\n",
      "|19-0000|463  |\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_soc5.join(soc2_map, df_soc5.soc5 == soc2_map.child, how='inner').groupBy(soc2_map.parent).count().show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of documents for each soc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|soc2   |count|\n",
      "+-------+-----+\n",
      "|47-0000|327  |\n",
      "|11-0000|3940 |\n",
      "|21-0000|586  |\n",
      "|45-0000|13   |\n",
      "|15-0000|3603 |\n",
      "|25-0000|660  |\n",
      "|17-0000|981  |\n",
      "|53-0000|9711 |\n",
      "|51-0000|800  |\n",
      "|43-0000|4379 |\n",
      "|49-0000|1246 |\n",
      "|27-0000|717  |\n",
      "|29-0000|7092 |\n",
      "|13-0000|2426 |\n",
      "|37-0000|459  |\n",
      "|55-0000|22   |\n",
      "|23-0000|145  |\n",
      "|31-0000|940  |\n",
      "|19-0000|463  |\n",
      "|39-0000|542  |\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fin.groupBy('soc2').count().show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of postings that were active on February 1st, 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18590'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(fin.where(( to_date(col(\"expired\")) >= lit(\"2017-02-01\"))).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could probably skip converting this to Pandas before saving it to the Sqlite database. Sqlite would not scale well for bigger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///test.db', echo=False)\n",
    "result_pdf = fin.select(\"*\").toPandas()\n",
    "result_pdf.to_sql('results', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"jdbc:sqlite:test.db\"\n",
    "#fin.write.jdbc(url=url, table=\"new_db\", mode=\"overwrite\", properties={\"driver\":\"org.sqlite.JDBC\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
