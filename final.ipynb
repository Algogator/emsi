{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, lit\n",
    "import lxml\n",
    "import lxml.etree\n",
    "import lxml.html\n",
    "from pyspark.sql.types import BooleanType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "import pandas\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"sample\")\n",
    "map_onet = spark.read.csv(\"map_onet_soc.csv\", header = \"true\")\n",
    "soc_heir = spark.read.csv(\"soc_hierarchy.csv\", header = \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|      onet|   soc5|\n",
      "+----------+-------+\n",
      "|11-1011.00|11-1011|\n",
      "|11-1011.03|11-1011|\n",
      "|11-1021.00|11-1021|\n",
      "|11-1031.00|11-1031|\n",
      "|11-2011.00|11-2011|\n",
      "|11-2011.01|11-2011|\n",
      "|11-2021.00|11-2021|\n",
      "|11-2022.00|11-2022|\n",
      "|11-2031.00|11-2031|\n",
      "|11-3011.00|11-3011|\n",
      "|11-3021.00|11-3021|\n",
      "|11-3031.00|11-3031|\n",
      "|11-3031.01|11-3031|\n",
      "|11-3031.02|11-3031|\n",
      "|11-3051.00|11-3051|\n",
      "|11-3051.01|11-3051|\n",
      "|11-3051.02|11-3051|\n",
      "|11-3051.03|11-3051|\n",
      "|11-3051.04|11-3051|\n",
      "|11-3051.05|11-3051|\n",
      "+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "map_onet.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wasn't sure if pre-processing the mappings is allowed but converting the soc_hierarchy.csv to a dictionary will ensure contant lookup time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=BooleanType())\n",
    "def detect_html(s):\n",
    "    try:\n",
    "        return lxml.html.fromstring(s).find('.//*') is not None\n",
    "            \n",
    "    except lxml.etree.ParserError as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of documents from which you successfully removed HTML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4010"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(detect_html('body')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=StringType())\n",
    "def detect_html(s):\n",
    "    try:\n",
    "        if lxml.html.fromstring(s).find('.//*') is not None:\n",
    "            return str(lxml.html.document_fromstring(s).text_content())\n",
    "        else:\n",
    "            return s\n",
    "            \n",
    "    except lxml.etree.ParserError as e:\n",
    "        return s\n",
    "\n",
    "df = df.withColumn('body',detect_html(col('body')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing an inner join may not be very scalable, I assumed the mapping would be constant and fixed. I would have liked to have the mapping in a dictionary which would allow constant lookup time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_soc5  = df.join(map_onet, on='onet', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------------+----------+----------+-----+--------------------+-------+\n",
      "|      onet|                body|               city|   expired|    posted|state|               title|   soc5|\n",
      "+----------+--------------------+-------------------+----------+----------+-----+--------------------+-------+\n",
      "|11-9199.00|Project Manager -...|             Laurel|2017-01-06|2016-12-07|   MD|Project Manager -...|11-9199|\n",
      "|13-1023.00|You can become an...|            Fairfax|2015-12-30|2015-11-30|   VA|Lease Purchase Dr...|13-1023|\n",
      "|19-3051.00|POSITION SUMMARY/...|      Ellicott City|2017-01-02|2016-12-03|   MD|Planning Supervis...|19-3051|\n",
      "|53-3032.00|Speak with a Recr...|            Jarales|2017-01-18|2016-12-19|   NM|Experienced Class...|53-3032|\n",
      "|11-3061.00|JOB SUMMARYThe Bu...|             Laredo|2017-01-02|2016-12-03|   TX|Buying Manager - ...|11-3061|\n",
      "|43-3021.02|Position Descript...|         Norristown|2017-03-23|2016-12-23|   PA|Senior Billing Re...|43-3021|\n",
      "|41-3031.02|Relationship bank...|          Los Altos|2016-12-16|2016-11-16|   CA|Greater South Bay...|41-3031|\n",
      "|35-3021.00|The Team Member i...|          Texarkana|2016-02-22|2016-01-23|   TX|Restaurant Team M...|35-3021|\n",
      "|41-2031.00|Position: Product...|           Appleton|2016-03-02|2016-02-01|   WI|Production Associate|41-2031|\n",
      "|13-1161.00|Requirements Pref...|        San Antonio|2016-12-28|2016-11-28|   TX|Program Marketing...|13-1161|\n",
      "|29-1141.00|Seeking Registere...|     Pleasant Ridge|2016-12-27|2016-11-27|   MI|     RN Travel Nurse|29-1141|\n",
      "|29-2091.00|Vacancy Identific...|        Martinsburg|2016-12-17|2016-11-17|   WV|Orthotist/Prosthe...|29-2091|\n",
      "|19-4099.01|Quality Assurance...|     Salt Lake City|2017-01-20|2016-12-21|   UT|Quality Assurance...|19-4099|\n",
      "|29-1141.00|Seeking Registere...|        East Quogue|2016-12-27|2016-11-27|   NY|     RN Travel Nurse|29-1141|\n",
      "|29-1141.00|Seeking Registere...|       San Elizario|2016-12-27|2016-11-27|   TX|     RN Travel Nurse|29-1141|\n",
      "|39-9031.00|Job Description:S...|          Ingleside|2016-12-17|2016-11-17|   TX|Personal Trainer ...|39-9031|\n",
      "|29-1141.00|Seeking Registere...|            Marquez|2016-12-27|2016-11-27|   TX|     RN Travel Nurse|29-1141|\n",
      "|43-4051.00|Position Informat...|      San Francisco|2017-01-22|2016-12-23|   CA|Customer Service ...|43-4051|\n",
      "|29-1141.00|Seeking Registere...|Grosse Ile Township|2016-12-27|2016-11-27|   MI|     RN Travel Nurse|29-1141|\n",
      "|41-1011.00|Generate Sales* P...|      Madeira Beach|2016-03-02|2016-02-01|   FL|  Lids Store Manager|41-1011|\n",
      "+----------+--------------------+-------------------+----------+----------+-----+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_soc5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of documents for each `soc2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed the soc2 code could be derived from the first two numbers in the soc5. I am assuming the there's a limit of 99-xxxx since this would break if it goes beyond 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = soc_heir.filter(col(\"level\") == 5).selectExpr(\"child as c5\", \"parent as p5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s4 = soc_heir.filter(col(\"level\") == 4).selectExpr(\"child as c4\", \"parent as p4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = soc_heir.filter(col(\"level\") == 3).selectExpr(\"child as c3\", \"parent as soc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = s5.join(s4, s4.c4 == s5.p5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc2_map = tmp.join(s3, tmp.p4 == s3.c3).selectExpr(\"c5 as soc5\",\"soc2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = df_soc5.join(soc2_map, on=\"soc5\", how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|soc2   |count|\n",
      "+-------+-----+\n",
      "|47-0000|326  |\n",
      "|11-0000|3940 |\n",
      "|21-0000|542  |\n",
      "|45-0000|13   |\n",
      "|15-0000|3603 |\n",
      "|25-0000|609  |\n",
      "|17-0000|981  |\n",
      "|51-0000|700  |\n",
      "|53-0000|9529 |\n",
      "|49-0000|1246 |\n",
      "|43-0000|4379 |\n",
      "|27-0000|717  |\n",
      "|29-0000|6960 |\n",
      "|13-0000|2233 |\n",
      "|37-0000|459  |\n",
      "|55-0000|22   |\n",
      "|23-0000|145  |\n",
      "|31-0000|940  |\n",
      "|39-0000|532  |\n",
      "|19-0000|463  |\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fin.groupBy('soc2').count().show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of postings that were active on February 1st, 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18322'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(fin.where(( to_date(col(\"expired\")) >= lit(\"2017-02-01\"))).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could probably skip converting this to Pandas before saving it to the Sqlite database. Sqlite would not scale well for bigger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///test.db', echo=False)\n",
    "sqlite_connection = engine.connect()\n",
    "result_pdf = fin.select(\"*\").toPandas()\n",
    "result_pdf.to_sql('results', con=sqlite_connection, index=False, if_exists='replace')\n",
    "sqlite_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"jdbc:sqlite:test.db\"\n",
    "#fin.write.jdbc(url=url, table=\"new_db\", mode=\"overwrite\", properties={\"driver\":\"org.sqlite.JDBC\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
